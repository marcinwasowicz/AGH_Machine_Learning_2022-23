{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5410db1b",
   "metadata": {},
   "source": [
    "# Introductory Example of Ensemble Learning in Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552fa67",
   "metadata": {},
   "source": [
    "### Define Single Teacher Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0a1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.linear3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.view(data.size(0), -1)  # flatten\n",
    "        output = F.relu(self.linear1(data))\n",
    "        output = F.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94454369",
   "metadata": {},
   "source": [
    "### Define Ensemble of Teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e35d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchensemble import BaggingClassifier, FusionClassifier\n",
    "\n",
    "teacher_ensemble = BaggingClassifier(\n",
    "    estimator=MLP,\n",
    "    n_estimators=10,\n",
    "    cuda=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39a6ef",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d95438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "train = datasets.MNIST(\"../Dataset\", train=True, download=True, transform=transform)\n",
    "test = datasets.MNIST(\"../Dataset\", train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22401127",
   "metadata": {},
   "source": [
    "### Load Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128922af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./params.json\", \"r\") as params_fd:\n",
    "    params = json.load(params_fd)\n",
    "\n",
    "TRAIN_TEACHERS = params[\"train_teachers\"]\n",
    "LR = params[\"lr\"]\n",
    "STUDENT_EPOCHS = params[\"student_epochs\"]\n",
    "TEACHER_EPOCHS = params[\"teacher_epochs\"]\n",
    "ALPHA = params[\"alpha\"]\n",
    "TEMPERATURE = params[\"temperature\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c32dd",
   "metadata": {},
   "source": [
    "### Offline Teacher Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f2696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.43\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_TEACHERS:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = {\"optimizer_name\": \"Adam\", \"lr\": 1e-3}\n",
    "\n",
    "    teacher_ensemble.set_criterion(criterion)\n",
    "    teacher_ensemble.set_optimizer(**optimizer)\n",
    "\n",
    "    print(\"Training Teacher Ensemble\")\n",
    "    teacher_ensemble.fit(train_loader, epochs=20, test_loader=test_loader)\n",
    "else:\n",
    "    from torchensemble.utils import io\n",
    "\n",
    "    io.load(teacher_ensemble, \".\")\n",
    "\n",
    "print(str(teacher_ensemble.evaluate(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee048f",
   "metadata": {},
   "source": [
    "### Define Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5b3c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 16)\n",
    "        self.linear2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.view(data.size(0), -1)  # flatten\n",
    "        output = F.relu(self.linear1(data))\n",
    "        output = self.linear2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53149bb0",
   "metadata": {},
   "source": [
    "### Implement Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea9705a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "def train_loop(student, train_loader, test_loader, epochs):\n",
    "    student.train()\n",
    "    optimizer = Adam(student.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_epoch_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            student_outputs = student(inputs)\n",
    "            loss = F.cross_entropy(student_outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_epoch_loss += loss.item()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = student(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, Loss: {total_epoch_loss}, Validation Accuracy: {100 * correct/total}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb055e",
   "metadata": {},
   "source": [
    "### Implement KD Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d91fcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kd_train_loop(student, teacher, temperature, train_loader, test_loader, epochs):\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "\n",
    "    optimizer = Adam(student.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_epoch_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                student_outputs / temperature, teacher_outputs / temperature\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_epoch_loss += loss.item()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = student(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, Loss: {total_epoch_loss}, Validation Accuracy: {100 * correct/total}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86020f13",
   "metadata": {},
   "source": [
    "### Train Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d837d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No teacher training\n",
      "Epoch: 0, Accuracy: 91.58, Loss: 217.10807114839554\n",
      "Epoch: 1, Accuracy: 92.24, Loss: 129.20910249650478\n",
      "Epoch: 2, Accuracy: 93.16, Loss: 113.32058991491795\n",
      "Epoch: 3, Accuracy: 93.77, Loss: 101.85108511894941\n",
      "Epoch: 4, Accuracy: 94.02, Loss: 93.68176006525755\n",
      "Epoch: 5, Accuracy: 94.43, Loss: 87.81360195577145\n",
      "Epoch: 6, Accuracy: 94.5, Loss: 83.12724731862545\n",
      "Epoch: 7, Accuracy: 94.88, Loss: 79.44343261048198\n",
      "Epoch: 8, Accuracy: 94.85, Loss: 76.5991804562509\n",
      "Epoch: 9, Accuracy: 94.71, Loss: 73.84392862021923\n",
      "Epoch: 10, Accuracy: 95.02, Loss: 70.94671323522925\n",
      "Epoch: 11, Accuracy: 95.21, Loss: 69.52563505247235\n",
      "Epoch: 12, Accuracy: 95.22, Loss: 67.35294060781598\n",
      "Epoch: 13, Accuracy: 95.27, Loss: 65.7399962823838\n",
      "Epoch: 14, Accuracy: 95.25, Loss: 63.78615561127663\n",
      "Epoch: 15, Accuracy: 95.3, Loss: 63.23735174909234\n",
      "Epoch: 16, Accuracy: 95.35, Loss: 61.72276658937335\n",
      "Epoch: 17, Accuracy: 95.52, Loss: 61.291945934295654\n",
      "Epoch: 18, Accuracy: 95.45, Loss: 60.18793055601418\n",
      "Epoch: 19, Accuracy: 95.04, Loss: 59.06139561533928\n",
      "Teacher Ensemble\n",
      "Epoch: 0, Loss: 42.21984642744064, Validation Accuracy: 89.71\n",
      "Epoch: 1, Loss: 16.855839926749468, Validation Accuracy: 91.39\n",
      "Epoch: 2, Loss: 14.446425409987569, Validation Accuracy: 92.06\n",
      "Epoch: 3, Loss: 13.43248488008976, Validation Accuracy: 92.51\n",
      "Epoch: 4, Loss: 12.740269646979868, Validation Accuracy: 92.68\n",
      "Epoch: 5, Loss: 12.166675977408886, Validation Accuracy: 92.98\n",
      "Epoch: 6, Loss: 11.644852775149047, Validation Accuracy: 93.14\n",
      "Epoch: 7, Loss: 11.179985163733363, Validation Accuracy: 93.51\n",
      "Epoch: 8, Loss: 10.774011795409024, Validation Accuracy: 93.57\n",
      "Epoch: 9, Loss: 10.407164475880563, Validation Accuracy: 93.59\n",
      "Epoch: 10, Loss: 10.08503240160644, Validation Accuracy: 93.92\n",
      "Epoch: 11, Loss: 9.800301063805819, Validation Accuracy: 94.05\n",
      "Epoch: 12, Loss: 9.546636623330414, Validation Accuracy: 94.33\n",
      "Epoch: 13, Loss: 9.298681683838367, Validation Accuracy: 94.42\n",
      "Epoch: 14, Loss: 9.107812863774598, Validation Accuracy: 94.53\n",
      "Epoch: 15, Loss: 8.923021947965026, Validation Accuracy: 94.64\n",
      "Epoch: 16, Loss: 8.7337830895558, Validation Accuracy: 94.72\n",
      "Epoch: 17, Loss: 8.593886354472488, Validation Accuracy: 94.7\n",
      "Epoch: 18, Loss: 8.446536329109222, Validation Accuracy: 94.79\n",
      "Epoch: 19, Loss: 8.327659705653787, Validation Accuracy: 94.92\n"
     ]
    }
   ],
   "source": [
    "student_1 = StudentMLP()\n",
    "student_2 = StudentMLP()\n",
    "\n",
    "print(\"No teacher training\")\n",
    "train_loop(student_1, train_loader, test_loader, 20)\n",
    "\n",
    "print(\"Teacher Ensemble\")\n",
    "kd_train_loop(\n",
    "    student_2,\n",
    "    teacher_ensemble,\n",
    "    TEMPERATURE,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    STUDENT_EPOCHS,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('agh_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "41b19489afcf2c7312096d4bb8c3c92e9eaa3192e5e7819118633a90bd50e0cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
